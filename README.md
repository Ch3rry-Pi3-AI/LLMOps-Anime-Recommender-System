# ğŸŒ¸ **LLMOps Anime Recommender System â€” Project Overview**

This repository presents a **fully operational LLMOps workflow** for an **anime recommendation system**, integrating all stages from **data ingestion and embedding generation** to **LLM reasoning**, **containerisation**, and **cloud deployment** on **Google Cloud Platform (GCP)** using **Docker** and **Kubernetes**.

<p align="center">
  <img src="img/streamlit/streamlit_app.gif" alt="Streamlit App Demo" width="100%">
</p>

## ğŸ§© **Grouped Stages**

| Stage                                   | Description                                                                                                                                          |
| :-------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------- |
| **00 â€” Project Setup**                  | Initialised the VS Code structure, virtual environment, and configuration files.                                                                     |
| **01â€“05 â€” Core LLM Logic**              | Built the data loader, vector store, prompt template, and recommender class, then unified them through a modular pipeline.                           |
| **06 â€” Streamlit Application**          | Developed an interactive front end for generating personalised anime recommendations.                                                                |
| **07 â€” Containerisation and Manifests** | Authored the Dockerfile and Kubernetes YAML manifests for deployment.                                                                                |
| **08 â€” GCP VM and Docker Setup**        | Configured a GCP Virtual Machine and installed Docker Engine for container management.                                                               |
| **09â€“11 â€” Cluster and Deployment**      | Installed Minikube and kubectl, configured networking and firewall rules, deployed the application to Kubernetes, and exposed it via an external IP. |
| **12 â€” Grafana Cloud Monitoring**       | Integrated Grafana Cloud for system metrics and real-time monitoring dashboards.                                                                     |

## ğŸ—‚ï¸ **Project Structure**

```text
llmops_anime_recommender_system/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ data/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ build_pipeline.py
â”‚   â””â”€â”€ recommendation_pipeline.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ prompt_template.py
â”‚   â””â”€â”€ recommender.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ img/
â”‚   â””â”€â”€ streamlit/streamlit_app.gif
â”œâ”€â”€ Dockerfile                 # Defines container image
â”œâ”€â”€ llmops-k8s.yaml            # Kubernetes Deployment + Service manifest
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```

## ğŸš€ **Summary**

The **LLMOps Anime Recommender System** showcases how a **retrieval-augmented generation (RAG)** pipeline can be transformed from concept to **production-grade deployment**.
It unites **LLM reasoning**, **vector-based retrieval**, and **prompt engineering** within a robust **DevOps and MLOps infrastructure**, serving as a foundational blueprint for future **scalable and monitored LLM applications**.