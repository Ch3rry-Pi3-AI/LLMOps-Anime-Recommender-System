# ğŸš¢ Containerisation & Kubernetes Deployment â€” LLMOps Anime Recommender System

This stage packages the app into a Docker image and provides a Kubernetes manifest to run it as a service. You can run the container locally for quick checks, then deploy it to a cluster (Minikube, kind, or a managed cloud).

## ğŸ—‚ï¸ Project Structure (Updated)

```text
llmops_anime_recommender_system/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ data/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ build_pipeline.py
â”‚   â””â”€â”€ recommendation_pipeline.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ prompt_template.py
â”‚   â””â”€â”€ recommender.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ img/
â”‚   â””â”€â”€ streamlit/streamlit_app.gif
â”œâ”€â”€ Dockerfile                 # New: container image definition
â”œâ”€â”€ llmops-k8s.yaml            # New: Deployment + Service manifest
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```

## ğŸ§± Build the Image

```bash
# From repo root
docker build -t llmops-app:latest .
```

Run locally to verify:

```bash
# Uses your .env for secrets; app serves on 8501
docker run --rm -p 8501:8501 --env-file .env llmops-app:latest
```

Open [http://localhost:8501](http://localhost:8501) to confirm itâ€™s up.

## ğŸ” Create Kubernetes Secrets

The manifest expects a secret named `llmops-secrets`. Create it from your `.env`:

```bash
kubectl create secret generic llmops-secrets --from-env-file=.env
```

If youâ€™re using a namespace, add `-n <your-namespace>` here and in all following commands.

## â˜¸ï¸ Deploy to Kubernetes

```bash
kubectl apply -f llmops-k8s.yaml
kubectl get pods
kubectl get svc llmops-service
```

The service is a `LoadBalancer`:

* **Minikube:** expose and open

  ```bash
  minikube image load llmops-app:latest
  minikube service llmops-service
  ```
* **kind:** load local image

  ```bash
  kind load docker-image llmops-app:latest
  kubectl apply -f llmops-k8s.yaml
  kubectl get svc llmops-service
  ```
* **Managed cloud (e.g., GKE/AKS/EKS):** ensure `image` points to a registry (e.g., `gcr.io/.../llmops-app:tag`) and that your nodes can pull it.

## ğŸ§© What the Manifest Does

* **Deployment**

  * Name: `llmops-app`
  * Image: `llmops-app:latest` with `IfNotPresent` (good for local clusters when you load the image)
  * Port: container listens on `8501`
  * Injects env vars from `llmops-secrets`

* **Service**

  * Name: `llmops-service`
  * Type: `LoadBalancer` for external access
  * Port: `80` â†’ `targetPort: 8501`

## ğŸ› ï¸ Tips and Troubleshooting

* **Local image not found by cluster**

  * Minikube: `minikube image load llmops-app:latest`
  * kind: `kind load docker-image llmops-app:latest`
  * Or push to a remote registry and update the `image:` in `llmops-k8s.yaml`.

* **Stuck on Pending External IP**

  * On local clusters, `LoadBalancer` may not provision an external IP. Use `minikube service llmops-service` or change the service to `NodePort`:

    ```yaml
    spec:
      type: NodePort
      ports:
        - port: 80
          targetPort: 8501
          nodePort: 30080
    ```

* **Secret updates**

  * Update `.env`, then:

    ```bash
    kubectl delete secret llmops-secrets
    kubectl create secret generic llmops-secrets --from-env-file=.env
    kubectl rollout restart deployment/llmops-app
    ```

* **Production notes**

  * Pin a specific image tag (e.g., `llmops-app:v1.0.0`), avoid `latest`.
  * Add `resources.requests/limits` and `readinessProbe`/`livenessProbe` if you need tighter reliability.

Thatâ€™s it for this stage: you now have a reproducible **Docker image** and a **Kubernetes manifest** to run the app consistently across environments.
