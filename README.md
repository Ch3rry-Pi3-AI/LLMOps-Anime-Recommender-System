# ğŸ” **Pipeline Orchestration â€” LLMOps Anime Recommender System**

This stage brings together all the **core backend workflows** of the **LLMOps Anime Recommender System**, combining data ingestion, embedding generation, and end-to-end anime recommendation logic.
It introduces two main pipelines â€” one for building the systemâ€™s vector database and another for producing live recommendations via the Groq-powered LLM.

## ğŸ—‚ï¸ **Project Structure (Updated)**

```text
llmops_anime_recommender_system/
â”œâ”€â”€ .env                             # ğŸ”‘ API keys (Groq & Hugging Face)
â”œâ”€â”€ .gitignore                       # ğŸš« Git ignore rules
â”œâ”€â”€ .python-version                  # ğŸ Python version pin for consistency
â”œâ”€â”€ app/                             # ğŸ¨ Streamlit application (to be developed)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py                    # âš™ï¸ Loads environment variables and model configuration
â”œâ”€â”€ data/                            # ğŸ“Š Contains raw and processed anime datasets
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ build_pipeline.py             # ğŸ—ï¸ Builds data and vector store pipeline
â”‚   â””â”€â”€ recommendation_pipeline.py    # ğŸ¤– Executes full recommendation workflow
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py               # ğŸ“¥ Loads and preprocesses anime data
â”‚   â”œâ”€â”€ vector_store_builder.py      # ğŸ§  Builds and loads the Chroma vector store
â”‚   â”œâ”€â”€ prompt_template.py           # ğŸ’¬ Defines structured LLM prompt
â”‚   â””â”€â”€ recommender.py               # ğŸ”— Connects retriever and Groq LLM via LCEL
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py          # Unified error handling
â”‚   â””â”€â”€ logger.py                    # Centralised logging setup
â”œâ”€â”€ pyproject.toml                   # ğŸ§© Project metadata and uv configuration
â”œâ”€â”€ requirements.txt                 # ğŸ“¦ Dependencies
â”œâ”€â”€ setup.py                         # ğŸ”§ Editable install support
â”œâ”€â”€ uv.lock                          # ğŸ”’ Dependency lock file
â””â”€â”€ README.md                        # ğŸ“– Documentation (you are here)
```

## âš™ï¸ **Overview of the Pipeline Stage**

### ğŸ—ï¸ `build_pipeline.py`

Automates the full data-to-vector workflow:

1. Loads and preprocesses the anime dataset using `AnimeDataLoader`.
2. Builds embeddings from processed text via `VectorStoreBuilder`.
3. Saves a persistent **Chroma vector store** for downstream retrieval.
4. Provides a reproducible foundation for all later inference steps.

**Example:**

```bash
python pipeline/build_pipeline.py
```

**Output:**

```
ğŸš€ Starting pipeline build...
âœ… Data successfully loaded and processed.
âœ… Vector store built and persisted successfully.
ğŸ¯ Pipeline build completed successfully.
```

### ğŸ¤– `recommendation_pipeline.py`

Implements the runtime recommendation logic:

1. Loads the stored **Chroma vector database**.
2. Initialises the **AnimeRecommender** class with the retriever, Groq LLM, and structured prompt.
3. Accepts user queries and returns detailed, context-aware anime recommendations.

**Example:**

```bash
python pipeline/recommendation_pipeline.py
```

**Sample Output:**

```
1. Violet Evergarden â€” A young woman trained as a weapon learns to write letters that connect people...
2. Clannad: After Story â€” A heartfelt exploration of love, loss, and family...
3. Your Lie in April â€” A touching story of music, grief, and personal growth...

Each of these anime explores emotional themes and strong character arcs.
```

## âœ… **In Summary**

The **pipeline stage** unifies the entire backend logic of the project:

* `build_pipeline.py` prepares and embeds the dataset into a Chroma vector store.
* `recommendation_pipeline.py` retrieves context and generates structured recommendations through the Groq LLM.

Together, they form the **operational core** of the LLMOps Anime Recommender System â€” seamlessly linking data, embeddings, and intelligent recommendations, and providing a robust backend for future Streamlit interface integration.
